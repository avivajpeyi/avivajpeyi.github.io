<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts | Avi Vajpeyi</title><link>https://avivajpeyi.github.io/post/</link><atom:link href="https://avivajpeyi.github.io/post/index.xml" rel="self" type="application/rss+xml"/><description>Posts</description><generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>Avi Vajpeyi © 2020</copyright><image><url>https://avivajpeyi.github.io/img/static/img/apex.png</url><title>Posts</title><link>https://avivajpeyi.github.io/post/</link></image><item><title>Merger Recoil Kicks</title><link>https://avivajpeyi.github.io/post/merger-recoil-kicks/</link><pubDate>Mon, 29 Jun 2020 01:20:45 +1000</pubDate><guid>https://avivajpeyi.github.io/post/merger-recoil-kicks/</guid><description>&lt;h1 id="recoil-kick-notes">Recoil kick notes&lt;/h1>
&lt;p>S190521g&amp;rsquo;s EM paper suggests v_kick ∼ 200 km/s&lt;/p>
&lt;p>&lt;a href="https://arxiv.org/pdf/gr-qc/0610154.pdf">https://arxiv.org/pdf/gr-qc/0610154.pdf&lt;/a> says ~ max v_kick ~ 175 . 2 ± 11 km/s for non spinning BH&lt;/p>
&lt;p>While precessing BH v_kick &amp;raquo; 1000 km/s &lt;a href="https://arxiv.org/abs/1908.04382">https://arxiv.org/abs/1908.04382&lt;/a>&lt;/p></description></item><item><title>Matched Filtering</title><link>https://avivajpeyi.github.io/post/matched-filtering/</link><pubDate>Mon, 29 Jun 2020 00:20:45 +1000</pubDate><guid>https://avivajpeyi.github.io/post/matched-filtering/</guid><description>&lt;h2>Table of Contents&lt;/h2>
&lt;nav id="TableOfContents">
&lt;ul>
&lt;li>&lt;a href="#a-conceptual-discussion">A Conceptual Discussion&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#matched-filtering-in-human-brains">Matched filtering in human brains&lt;/a>&lt;/li>
&lt;li>&lt;a href="#matched-filtering-in-ligo-data">Matched filtering in LIGO data&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#the-maths">The maths&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#optimal-detection-statistic">Optimal detection statistic&lt;/a>&lt;/li>
&lt;li>&lt;a href="#gaussian-noise">Gaussian noise&lt;/a>&lt;/li>
&lt;li>&lt;a href="#matched-filter">Matched-Filter&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#the-code">The code&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#defining-signals-and-noise">Defining signals and noise&lt;/a>&lt;/li>
&lt;li>&lt;a href="#defining-the-matched-filtering-code">Defining the matched-filtering code&lt;/a>&lt;/li>
&lt;li>&lt;a href="#examples-of-matched-filtering">Examples of matched-filtering&lt;/a>&lt;/li>
&lt;li>&lt;a href="#code-for-demo">Code for demo&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/nav>
&lt;h2 id="a-conceptual-discussion">A Conceptual Discussion&lt;/h2>
&lt;h3 id="matched-filtering-in-human-brains">Matched filtering in human brains&lt;/h3>
&lt;p>Human brains do a form of matched filtering when brains classify certain sounds as &amp;lsquo;words&amp;rsquo;. Eardrums are vibrated by sound
waves and brains compare these sound waves to other template sound waves that are known. In the case of words, brains
compare the sound waves with a bank of sound waves from learned words. This process is similar to how LIGO data analysts use
matched filtering to find gravitational waves in LIGO data.&lt;/p>
&lt;h3 id="matched-filtering-in-ligo-data">Matched filtering in LIGO data&lt;/h3>
&lt;p>Compact binary coalesence (CBC) searches like
&lt;a href="pycbc">PyCBC&lt;/a> use &lt;em>matched filtering&lt;/em> to find gravitational wave signals in LIGO strain data. This method compares a gravitational wave template (numerical values representing one perticular gravitational wave) to strain data. Before the strain data is compared to the gravitational wave template, the data is weighed based on the detector&amp;rsquo;s sensitivity (lower the weight of the data that comes from a region where the detector is not sensitive). The output of matched-filtering is a signal-to-noise ratio (SNR) that can be used to determine if the data contains something interesting (a potential gravitational wave candidate) or just noise.&lt;/p>
&lt;p>There are many possible gravitational wave templates (gravitational waves from CBCs can have 15 parameters that can describe them hence there are $O(n^{15})$ possible templates). To compute a matched-filter SNR for each of these templates with the LIGO data is computationally expensive. Hence, instead of match-filtering with all templates, only a subset of templates to be used in matched-filtering is selected and stored in a &lt;em>template bank&lt;/em>. The bank is created to cover as much of the parameter space as possible by storing only the unique looking templates.&lt;/p>
&lt;figure id="figure-an-example-template-bank-used-by-ligo-searches">
&lt;a data-fancybox="" href="https://avivajpeyi.github.io/post/matched-filtering/example_bank_huf1562fd73a0e497989eef78c62a97bdb_306564_2000x2000_fit_lanczos_2.png" data-caption="An example template bank used by LIGO searches.">
&lt;img data-src="https://avivajpeyi.github.io/post/matched-filtering/example_bank_huf1562fd73a0e497989eef78c62a97bdb_306564_2000x2000_fit_lanczos_2.png" class="lazyload" alt="" width="916" height="696">
&lt;/a>
&lt;figcaption>
An example template bank used by LIGO searches.
&lt;/figcaption>
&lt;/figure>
&lt;h2 id="the-maths">The maths&lt;/h2>
&lt;h3 id="optimal-detection-statistic">Optimal detection statistic&lt;/h3>
&lt;p>The first question LIGO data analysts ask when they receive LIGO strain data $s(t)$ is:&lt;/p>
&lt;blockquote>
&lt;p>Does the $s(t)$ consist only of noise $n(t)$ or does $s(t)$ contain a gravitational wave signal $h(t)$ hidden in the noise?&lt;/p>
&lt;/blockquote>
&lt;p>The two situations are two different hypotheses about the strain data:&lt;/p>
&lt;ul>
&lt;li>Null Hypothesis, $\mathcal{H}_{n}: n(t) = s(t)$, and&lt;/li>
&lt;li>GW Hypothesis, $\mathcal{H}_{GW}: n(t) = s(t) - h(t)$.&lt;/li>
&lt;/ul>
&lt;p>
&lt;a href="https://en.wikipedia.org/wiki/Bayes%27_theorem" target="_blank" rel="noopener">Bayes theorem&lt;/a> can answer which of the two hypotheses are favoured by the data with an odds ratio:
\begin{equation} \label{eq:odds}
\begin{split}
\mathcal{O}(\mathcal{H}&lt;em>{GW}| s) &amp;amp; = \frac{P(\mathcal{H}&lt;/em>{GW}|s)}{ P(\mathcal{H}_{n} | s)} .
\end{split}
\end{equation}&lt;/p>
&lt;p>This odds ratio is the &lt;em>optimal detection statistic&lt;/em> that expresses the value of the probability
that the data contains the anticipated signal be calculated when&lt;/p>
&lt;ol>
&lt;li>the statistical properties of the noise process are known&lt;/li>
&lt;li>the exact form of the signal is known&lt;/li>
&lt;/ol>
&lt;p>The following subsections describe in detail the statistical properties of the noise and signal that permit LIGO data analysts to calculate $\mathcal{O}(\mathcal{H}| s)$.&lt;/p>
&lt;h3 id="gaussian-noise">Gaussian noise&lt;/h3>
&lt;p>To simplify the ability to make a detection, noise $n(t)$ is assumed to be [stationary Gaussian white noise].
For Gaussian white noise time series data that is sampled at regular intervals of $\Delta t$, the probability of collecting a set of $N$
datapoints $\vec{n}$, where
$$\vec{n} = \{n_0(t=0), n_1(t=\Delta t), n_2(t=2 \Delta t), &amp;hellip;, n_{N-1}(t= (N-1) \Delta t) \}$$
from $0\leq t\leq T$, can be written as:
\begin{equation} \label{eq:gaussian}
\begin{split}
p_n(\vec{n}) &amp;amp;= \prod^{N-1}_0 \frac{1}{\sigma\sqrt{2\pi}}\ \text{exp}\left( \frac{-1}{2\sigma^2} n_i^2 \right) \\&lt;br>
&amp;amp;= \frac{1}{(\sigma\sqrt{2\pi})^N}\ \text{exp}\left( \frac{-1}{2\sigma^2} \sum^{N-1}_{i=0} n_i^2 \right)
\end{split}
\end{equation}
the following subsections delve into the maths required to simplify this.&lt;/p>
&lt;h4 id="summing-samples">Summing samples&lt;/h4>
&lt;p>For $\lim {\Delta t \to 0}$, $\sum^{N}_{i=1} n_i^2$ turns into an integral:&lt;/p>
&lt;p>\begin{equation} \label{eq:gauss_limit}
\begin{split}
\lim_{\Delta t \to 0} \sum^{N}_{i=1} n_i^2 \Delta t &amp;amp;= \int^T_0 n^2(t) dt \\&lt;br>
&amp;amp;= \text{(Parseval&amp;rsquo;s Theorem and assume $0 \to T$ very large?)} \\&lt;br>
&amp;amp;\approx \int^{-\infty}_{+\infty} |\widetilde{n}(f)|^2 df
\end{split}
\end{equation}&lt;/p>
&lt;h4 id="autocorrelation-function-for-gaussian-noise">Autocorrelation function for Gaussian Noise&lt;/h4>
&lt;p>Additionally, as $\lim {\Delta t \to 0}$, we can also get an expression for the &lt;em>autocorrelation function&lt;/em>.&lt;/p>
&lt;div class="alert alert-note">
&lt;div>
&lt;p>&lt;strong>Autocorrelation Function:&lt;/strong>&lt;/p>
&lt;p>The autocorrelation function is a tools used to find patterns in time-series data. There are two types:&lt;/p>
&lt;ol>
&lt;li>Ensemble autocorrelation: quantifies correclation between points after repeated trials&lt;/li>
&lt;li>Temporal autocorrelation: quantifies correlation between points separated by various time lags in the same time-series&lt;/li>
&lt;/ol>
&lt;p>As points become more separated, typically the temporal autocorrelation function should go to 0 (since it is difficult to to forecast further into the future from a given set of data).&lt;/p>
&lt;p>For a continuous-time signal $y(t)$ and a lag of $\tau$, the temporal autocorreclation $R^T_{yy}(\tau)$ is given by:
$$ R^T_{yy}(\tau) = \int^{+\infty}_{-\infty} y(t) y^*(t-\tau)\ ,$$
and the ensemble autocorrelation $R^E_{yy}(\tau)$ is given by:
$$ R^E_{yy}(\tau) = \langle y(t)|y(t-\tau)\rangle. $$&lt;/p>
&lt;p>If the signal is &lt;em>erodic&lt;/em> (ie the signal&amp;rsquo;s statistical properties can be deduced from a long set of random samples), then
$$ R^T_{yy}(\tau) =\lim_{T\to \infty} \frac{1}{T} \int^{T}_{0} y(t) y^*(t-\tau)dt = R^E_{yy}(\tau) .$$&lt;/p>
&lt;p>Finally, note that the units ot $R$ are that of power! Hence, this can be used in the calculation of
a power spectral density.&lt;/p>
&lt;/div>
&lt;/div>
&lt;p>At $\lim {\Delta t \to 0}$, the autocorrelation function for $n(t)$ becomes
\begin{equation} \label{eq:gauss_autocorrelation_temporal}
\begin{split}
R^T_{nn}(\tau=\Delta t) &amp;amp;= \lim_{T\to \infty} \frac{1}{T} \int^{T}_{0} n(t) n^*(t-\Delta t)dt \\&lt;br>
&amp;amp;= \lim_{T\to \infty} \frac{1}{T} \int^{T}_{0} |n(t)|^2 dt \\&lt;br>
&amp;amp;= A\delta(\tau)
\end{split}
\end{equation}&lt;/p>
&lt;p>To determine $A$, we need to consider $R^E_{nn}$. Note for a random process $x(\theta)$,
$$ \langle x(\theta)|x(\theta) \rangle = \mu$$
$$ \langle (x(\theta)-\mu)^2| (x(\theta)-\mu)^2 \rangle = \sigma^2$$
Hence, for Gaussian white noise where $\mu=0$,&lt;/p>
&lt;p>\begin{equation} \label{eq:gauss_autocorrelation_ensemble}
\begin{split}
\sigma^2 &amp;amp;= \langle (n(t)-\mu)^2| (n(t)-\mu)^2 \rangle\rangle \\&lt;br>
&amp;amp;= \langle n^2(t)| n^2(t) \rangle\rangle \\&lt;br>
&amp;amp;= R^E_{nn}(\tau) \\&lt;br>
&amp;amp;= A
\end{split}
\end{equation}&lt;/p>
&lt;p>Thus,
$$R_{nn}(\tau)=\sigma^2\delta(\tau) $$&lt;/p>
&lt;h4 id="power-spectral-density-from-autocorrelation">Power spectral density from autocorrelation&lt;/h4>
&lt;p>The one-sided power spectral density $\text{PSD}(f)$ (of a signal $n(t)$) is defined as twice the Fourier transform of the noise autocorrelation function:
\begin{equation} \label{eq:psd_calc}
\begin{split}
\text{PSD}(f) &amp;amp;= 2 \mathcal{F}(R_{nn}(t))) \\&lt;br>
&amp;amp;= 2 \int_{-\infty}^{+\infty}R_{nn}(\tau) e^{-if\tau}d\tau
\end{split}
\end{equation}&lt;/p>
&lt;div class="alert alert-note">
&lt;div>
&lt;strong>Derivation of the above PSD equation&lt;/strong> (&lt;em>taken from Mike Lau&amp;rsquo;s master&amp;rsquo;s thesis&lt;/em>)
\begin{equation} \label{eq:psd_derivation}
\begin{split}
\mathcal{F}(R_{nn}(t))) &amp;amp;= \langle \tilde{n}^*(f) \tilde{n}(f&amp;rsquo;)\rangle\\&lt;br>
&amp;amp;= \iint^{\infty}_{-\infty} \langle {n}(t) {n}(t&amp;rsquo;)\rangle e^{-2\pi i (ft-f&amp;rsquo;t&amp;rsquo;)} dt dt&amp;rsquo;\\&lt;br>
&amp;amp;{t&amp;rsquo;\to t+t&amp;rsquo;}\\&lt;br>
&amp;amp;=\iint^{\infty}_{-\infty} \langle {n}(t) {n}(t+t&amp;rsquo;)\rangle e^{-2\pi i(f-f&amp;rsquo;)t} e^{-2\pi if&amp;rsquo;t&amp;rsquo;} dt dt&amp;rsquo;\\&lt;br>
&amp;amp;=\int^{\infty}_{-\infty} \langle {n}(t) {n}(t+t&amp;rsquo;)\rangle e^{-2\pi if&amp;rsquo;t&amp;rsquo;} dt&amp;rsquo; \delta(f-f&amp;rsquo;) \\&lt;br>
&amp;amp;= \frac{1}{2}\text{PSD}(f)\delta(f-f&amp;rsquo;) \\ &lt;br>
\end{split}
\end{equation}
&lt;/div>
&lt;/div>
&lt;p>In the case where $\lim {\Delta t \to 0}$,
$$R_{nn}(\tau)=\sigma^2\delta(\tau) = R_{nn}(f), $$
hence,
$$\text{PSD}(f) = \lim_{\Delta t \to 0} 2\sigma^2 \Delta t$$&lt;/p>
&lt;h4 id="gaussian-noise-at-lim-delta-t-to-0">Gaussian noise at $\lim {\Delta t \to 0}$&lt;/h4>
&lt;p>Finally, putting the above together, the probability of collecting a set of $N$
datapoints $\vec{n}$ from Guassian white noise is simplified to:
\begin{equation} \label{eq:gaussian_prob}
\begin{split}
p_n(\vec{n}) &amp;amp;= \lim_{\Delta t \to 0}\frac{1}{(\sigma\sqrt{2\pi})^N}\ \text{exp}\left( \frac{-1}{2\sigma^2} \sum^{N-1}_{i=0} n_i^2\right) \\&lt;br>
&amp;amp;\propto \lim_{\Delta t \to 0} \text{exp}\left( \frac{-1}{2\sigma^2\Delta t} \sum^{N-1}_{i=0} n_i^2 \Delta t\right) \\&lt;br>
&amp;amp;\propto \text{exp}\left( \frac{-1}{\text{PSD}(f)} \int^{T}_{0} n(t)^2 dt\right) \\&lt;br>
&amp;amp;\propto \text{exp}\left( - \int^{\infty}_{-\infty} \frac{|n(f)|^2}{\text{PSD}(f)} df\right) \\&lt;br>
&amp;amp;\propto \text{exp}\left(-\frac{1}{2} 4 \int^{\infty}_{0} \frac{|n(f)|^2}{\text{PSD}(f)} df\right) \\&lt;br>
\therefore p_n(\vec{n}) &amp;amp;\propto \text{e}^{-(n,n)/2}
\end{split}
\end{equation}&lt;/p>
&lt;div class="alert alert-note">
&lt;div>
*&lt;em>Noise Weighted Inner product of two time-series **
The noise weighted inner product $(a,b)$ of two time-series $a(t)$ and $b(t)$ is defined as
\begin{equation} \label{eq:inner_producs}
\begin{split}
(a,b) &amp;amp;= 4 \text{Re} \int_0^{\infty} \frac{\tilde{a}(f) \tilde{b}^&lt;/em>(f)}{\text{PSD}(f)}df\\&lt;br>
&amp;amp;= 2 \int_{-\infty}}^{\infty} \frac{\tilde{a}(f) \tilde{b}^*(f)}{\text{PSD}(|f|)}df\\&lt;br>
&amp;amp;= \int_{-\infty}}^{\infty} \frac{\tilde{a}(f) \tilde{b}^*(f) + \tilde{a}^*(f) \tilde{b}(f)}{\text{PSD}(|f|)}df,
\end{split}
\end{equation}
&lt;/div>
&lt;/div>
&lt;p>where&lt;/p>
&lt;ul>
&lt;li>$\text{PSD}(f) is the one-sided power spectral density of noise, and&lt;/li>
&lt;li>$\tilde{y}(-f) = \tilde{y}^*(f)$ .&lt;/li>
&lt;/ul>
&lt;h3 id="matched-filter">Matched-Filter&lt;/h3>
&lt;p>The above section provides a mathematical perscription to calculate the probability desnsity that
a collection of time-series data comes from stationary Gaussian white noise. Using this,
the probability density of getting some data given $\matchcal{H}&lt;em>{n}$ and the probability density of getting some data given $\matchcal{H}&lt;/em>{GW}$
can be calculated:&lt;/p>
&lt;ul>
&lt;li>$p(s|\mathcal{H}_{n}:n=s) \propto \text{e}^{-(s,s)/2}$&lt;/li>
&lt;li>$p(s|\mathcal{H}_{GW}:s=s-h) \propto \text{e}^{-(s-h,s-h)/2}$&lt;/li>
&lt;/ul>
&lt;p>Finally, going off of the odd&amp;rsquo;s ratio, we can calculate a likelihood ratio:&lt;/p>
&lt;p>\begin{equation} \label{eq:likelihood_ratio}
\begin{split}
\Lambda(\mathcal{H}&lt;em>{GW}| s) &amp;amp;= \frac{p(s|\mathcal{H}&lt;/em>{GW}|s)}{ p(s|\mathcal{H}_{n})} \\&lt;br>
&amp;amp;= \frac{\text{e}^{-(s-h,s-h)/2}}{\text{e}^{-(s,s)/2} \\&lt;br>
&amp;amp;= \text{e}^{(s,h)}\text{e}^{-(h,h)/2}
\end{split}
\end{equation}&lt;/p>
&lt;p>Note that:&lt;/p>
&lt;ul>
&lt;li>$\Lambda(\mathcal{H}_{GW}| s)$ depends on the data $s(t)$ only through $(s, h)$&lt;/li>
&lt;li>$\Lambda(\mathcal{H}_{GW}| s)$ is a monotonically increasing function of this $(s, h)$.&lt;/li>
&lt;/ul>
&lt;p>$\therefore (s,h)$ is the &lt;em>optimal detection statistic&lt;/em>: any choice of threshold on the required odds ratio for accepting the alternative hypothesis can be translated to a threshold on the value of $(s, h)$. This inner produc is the &lt;em>matched filter&lt;/em> since it is a noise-weighted correlation of the anticipated signal with the data.&lt;/p>
&lt;h2 id="the-code">The code&lt;/h2>
&lt;p>As discussed above, one method of searching for a specific signal in a noisy data is via a matched filter. The code for this is illustrated in this section.&lt;/p>
&lt;h3 id="defining-signals-and-noise">Defining signals and noise&lt;/h3>
&lt;p>Here is the python code to generate Gaussain pulses, square pulses and noise.&lt;/p>
&lt;pre>&lt;code class="language-python">def get_gaussian_pulse_signal(time: np.ndarray) -&amp;gt; np.ndarray:
sig = scipy.signal.gausspulse(t=time, fc=5)
sig[np.abs(sig) &amp;lt; 1e-2] = 0
return sig
def get_square_pulse_signal(time: np.ndarray) -&amp;gt; np.ndarray:
idx_to_one = np.abs(time) &amp;lt;= 0.5
sig = np.array([1 if one else 0 for one in idx_to_one])
return sig
def get_noise(time: np.ndarray, noise_factor: Optional[float] = 2) -&amp;gt; np.ndarray:
noise = np.random.randn(1, len(time)) * noise_factor
return noise[0]
&lt;/code>&lt;/pre>
&lt;p>The data generated from Gaussian noise and a Gaussian Pulse signal is shown in the following image.
&lt;figure id="figure-a-demonstrative-image-showing-what-happens-to-a-gaussian-pulse-signal-when-some-noise-is-added-to-it">
&lt;a data-fancybox="" href="https://avivajpeyi.github.io/post/matched-filtering/data_huc79dad2933094a5bf23c1ca19d9dd784_53716_2000x2000_fit_lanczos_2.png" data-caption="A demonstrative image showing what happens to a Gaussian Pulse signal when some noise is added to it.">
&lt;img data-src="https://avivajpeyi.github.io/post/matched-filtering/data_huc79dad2933094a5bf23c1ca19d9dd784_53716_2000x2000_fit_lanczos_2.png" class="lazyload" alt="" width="640" height="480">
&lt;/a>
&lt;figcaption>
A demonstrative image showing what happens to a Gaussian Pulse signal when some noise is added to it.
&lt;/figcaption>
&lt;/figure>
&lt;/p>
&lt;h3 id="defining-the-matched-filtering-code">Defining the matched-filtering code&lt;/h3>
&lt;p>Here is a rudimentary implementation of a matched-filter method, where the data is multiplied with the template, and the convolution is summed.&lt;/p>
&lt;pre>&lt;code class="language-python">def perform_matched_filter(
time: np.ndarray,
data: np.ndarray,
template_func: Callable
) -&amp;gt; Dict:
match_filter_values = []
template = move_template_to_lowest_time(t=template_func(time))
for i in range(0, len(data), 10):
current_template = np.roll(template, shift=i)
matched_filter = sum(data * current_template)
match_filter_values.append(dict(
matched_filter=matched_filter,
time=time[i],
template=current_template
))
return match_filter_values
&lt;/code>&lt;/pre>
&lt;h3 id="examples-of-matched-filtering">Examples of matched-filtering&lt;/h3>
&lt;h4 id="finding-a-gaussian-pulse-with-a-gaussian-pulse-template">Finding a Gaussian Pulse with a Gaussian Pulse Template&lt;/h4>
&lt;div class="fixed-wrapper">
&lt;iframe style="height: 700px; width: 100%; min-width: 360px; max-width: 590px;" frameborder="0" allowtransparency="true" scrolling="no" src="gaussian_pulse.html">&lt;/iframe>
&lt;/div>
&lt;h4 id="finding-a-gaussian-pulse-with-a-square-template">Finding a Gaussian Pulse with a Square Template&lt;/h4>
&lt;div class="fixed-wrapper">
&lt;iframe style="height: 700px; width: 100%; min-width: 360px; max-width: 590px;" frameborder="0" allowtransparency="true" scrolling="no" src="square.html">&lt;/iframe>
&lt;/div>
&lt;h4 id="finding-a-square-with-a-gaussian-pulse-template">Finding a Square with a Gaussian Pulse Template&lt;/h4>
&lt;div class="fixed-wrapper">
&lt;iframe style="height: 700px; width: 100%; min-width: 360px; max-width: 590px;" frameborder="0" allowtransparency="true" scrolling="no" src="gaussian_pulse_to_find_square.html">&lt;/iframe>
&lt;/div>
&lt;h3 id="code-for-demo">Code for demo&lt;/h3>
&lt;p>The entire code for the demo can be found here:
&lt;script type="application/javascript" src="https://gist.github.com/avivajpeyi/c5fbcdabc5a52b3fd039075f98fcd563.js">&lt;/script>
&lt;/p></description></item><item><title>Colorblind Palette for Plotting</title><link>https://avivajpeyi.github.io/post/colorblind-palette-for-plotting/</link><pubDate>Fri, 19 Jun 2020 00:20:45 +1000</pubDate><guid>https://avivajpeyi.github.io/post/colorblind-palette-for-plotting/</guid><description>&lt;script type="application/javascript" src="https://gist.github.com/avivajpeyi/6cafec9c0ffa70b0bd72b7ee85e995d1.js">&lt;/script>
&lt;figure id="figure-20-colorblind-cols-note-the-colors-are-very-similar-after-10">
&lt;a data-fancybox="" href="https://avivajpeyi.github.io/post/colorblind-palette-for-plotting/example_colorblind_cols_huf7e7db2a8672f1d7016a6ba445fb678c_8259_2000x2000_fit_lanczos_2.png" data-caption="20 colorblind cols. Note the colors are very similar after ~10.">
&lt;img data-src="https://avivajpeyi.github.io/post/colorblind-palette-for-plotting/example_colorblind_cols_huf7e7db2a8672f1d7016a6ba445fb678c_8259_2000x2000_fit_lanczos_2.png" class="lazyload" alt="" width="2241" height="160">
&lt;/a>
&lt;figcaption>
20 colorblind cols. Note the colors are very similar after ~10.
&lt;/figcaption>
&lt;/figure></description></item><item><title>Python Big-O Examples</title><link>https://avivajpeyi.github.io/post/python-big-o-examples/</link><pubDate>Fri, 19 Jun 2020 00:20:45 +1000</pubDate><guid>https://avivajpeyi.github.io/post/python-big-o-examples/</guid><description>&lt;h1 id="what-are-the-big-o-for-the-following">What are the Big-O for the following?&lt;/h1>
&lt;p>Some students in an Algorithms class I am teaching are having trouble with
Big-O notation. Here are some practice problems:&lt;/p>
&lt;h2 id="qs-1">Qs 1&lt;/h2>
&lt;pre>&lt;code class="language-python">for i in range(n):
sum++
&lt;/code>&lt;/pre>
&lt;div class="container">
&lt;a href="#qs1" class="btn btn-info" data-toggle="collapse">Answer&lt;/a>
&lt;div id="qs1" class="collapse">
O(n)
&lt;/div>
&lt;/div>
&lt;h2 id="qs-2">Qs 2&lt;/h2>
&lt;pre>&lt;code class="language-python">for i in range(n)
for j in range(n)
sum+=1
&lt;/code>&lt;/pre>
&lt;div class="container">
&lt;a href="#qs2" class="btn btn-info" data-toggle="collapse">Answer&lt;/a>
&lt;div id="qs2" class="collapse">
O(n)
&lt;/div>
&lt;/div>
&lt;h2 id="qs-3">Qs 3&lt;/h2>
&lt;pre>&lt;code class="language-python">for i in range(n, - 1, -1):
sum +=1
&lt;/code>&lt;/pre>
&lt;div class="container">
&lt;a href="#qs3" class="btn btn-info" data-toggle="collapse">Answer&lt;/a>
&lt;div id="qs3" class="collapse">
O(n^2)
&lt;/div>
&lt;/div>
&lt;h2 id="qs-4">Qs 4&lt;/h2>
&lt;pre>&lt;code class="language-python">i = 1
while i&amp;lt;n:
i *= 2
&lt;/code>&lt;/pre>
&lt;div class="container">
&lt;a href="#qs4" class="btn btn-info" data-toggle="collapse">Answer&lt;/a>
&lt;div id="qs4" class="collapse">
O(2^n)
&lt;/div>
&lt;/div>
&lt;h2 id="qs-5">Qs 5&lt;/h2>
&lt;pre>&lt;code class="language-python">i = n
while (i &amp;lt; n)
i ++
&lt;/code>&lt;/pre>
&lt;div class="container">
&lt;a href="#qs5" class="btn btn-info" data-toggle="collapse">Answer&lt;/a>
&lt;div id="qs5" class="collapse">
O(1)
&lt;/div>
&lt;/div>
&lt;h2 id="qs-6">Qs 6&lt;/h2>
&lt;pre>&lt;code class="language-python">def fibonacci(n):
if (n &amp;lt;= 1): return n
else: return(fibonacci(n - 2) + fibonacci(n -1))
&lt;/code>&lt;/pre>
&lt;div class="container">
&lt;a href="#qs6" class="btn btn-info" data-toggle="collapse">Answer&lt;/a>
&lt;div id="qs6" class="collapse">
O(2^n)
&lt;/div>
&lt;/div>
&lt;h2 id="qs-7">Qs 7&lt;/h2>
&lt;pre>&lt;code class="language-python">i = 0
while (i &amp;gt; n)
i *= 2
&lt;/code>&lt;/pre>
&lt;div class="container">
&lt;a href="#qs7" class="btn btn-info" data-toggle="collapse">Answer&lt;/a>
&lt;div id="qs7" class="collapse">
O(1)
&lt;/div>
&lt;/div>
&lt;h2 id="qs-8">Qs 8&lt;/h2>
&lt;pre>&lt;code class="language-python">for(int i=n; i&amp;gt;0; i/=2)
for(int j=0; j&amp;lt;i; j++)
count++;
&lt;/code>&lt;/pre>
&lt;div class="container">
&lt;a href="#qs8" class="btn btn-info" data-toggle="collapse">Answer&lt;/a>
&lt;div id="qs8" class="collapse">
O(n)
&lt;/div>
&lt;/div>
&lt;h2 id="qs-9">Qs 9&lt;/h2>
&lt;pre>&lt;code class="language-python">for(int i=1; i&amp;lt;n*n; i++)
for(int j=1; j≤i; j++)
for(int k=1; k≤ 6; k++)
sum ++;
&lt;/code>&lt;/pre>
&lt;div class="container">
&lt;a href="#qs9" class="btn btn-info" data-toggle="collapse">Answer&lt;/a>
&lt;div id="qs9" class="collapse">
O(n^4)
&lt;/div>
&lt;/div></description></item><item><title>PhD Reports</title><link>https://avivajpeyi.github.io/post/phd-reports/</link><pubDate>Fri, 10 Apr 2020 00:20:45 +1000</pubDate><guid>https://avivajpeyi.github.io/post/phd-reports/</guid><description>&lt;p>For my PhD canditure I have to produce some reports documenting my progress:&lt;/p>
&lt;ul>
&lt;li>6 months:
&lt;a href="https://avi.vajpeyi.docs.ligo.org/initial_review/" target="_blank" rel="noopener">Initial Project Review Report&lt;/a>&lt;/li>
&lt;li>12 months:
&lt;a href="https://avi.vajpeyi.docs.ligo.org/confirmation_review/" target="_blank" rel="noopener">Confirmation Report&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>Note: to view these documents you may have to click on &amp;ldquo;Advanced &amp;gt; Proceed&amp;rdquo;.&lt;/p></description></item><item><title>Installing LalSuite from Source</title><link>https://avivajpeyi.github.io/post/installing-lalsuite-from-source/</link><pubDate>Thu, 19 Sep 2019 00:20:45 +1000</pubDate><guid>https://avivajpeyi.github.io/post/installing-lalsuite-from-source/</guid><description>&lt;h2 id="steps">Steps&lt;/h2>
&lt;h3 id="step-0-requirements">Step 0: Requirements&lt;/h3>
&lt;p>Module loads/things you might need:&lt;/p>
&lt;pre>&lt;code class="language-bash">module load git/2.18.0
module load git-lfs/2.4.0
module load anaconda3/5.1.0
module load gcc/6.4.0
module load openmpi/3.0.0
module load fftw/3.3.7
module load swig/3.0.12-python-3.6.4
module load framel/8.30
module load metaio/8.4.0
module load gsl/2.4
&lt;/code>&lt;/pre>
&lt;h3 id="step-1-install-lal">Step 1: Install lal&lt;/h3>
&lt;pre>&lt;code class="language-bash">git clone git@git.ligo.org:lscsoft/lalsuite.git
mkdir lal_install_dir
cd lalsuite/lal
./00boot &amp;amp;&amp;amp; ./configure --prefix=/&amp;lt;path to&amp;gt;/lal_install_dir/ &amp;amp;&amp;amp; make &amp;amp;&amp;amp; make install
. &amp;lt;path to&amp;gt;/lal_install_dir/etc/lal-user-env.sh
&lt;/code>&lt;/pre>
&lt;h3 id="step-2-install-lalsimulation">Step 2: Install lalsimulation&lt;/h3>
&lt;pre>&lt;code class="language-bash">cd ../lalsimulation
./00boot &amp;amp;&amp;amp; ./configure --prefix=/&amp;lt;path to&amp;gt;/lal_install_dir/ &amp;amp;&amp;amp; make &amp;amp;&amp;amp; make install
&amp;lt;path to&amp;gt;/lal_install_dir/etc/lalsimulation-user-env.sh
&lt;/code>&lt;/pre>
&lt;p>At this point, the installation &lt;em>should(?)&lt;/em> work. Test it out in python:&lt;/p>
&lt;pre>&lt;code class="language-bash">cd ~
python
&amp;gt;&amp;gt;&amp;gt; import lalsimulation
&lt;/code>&lt;/pre>
&lt;h3 id="step-3-get-waveform-data">Step 3: Get waveform data&lt;/h3>
&lt;pre>&lt;code class="language-bash">cd ~/ &amp;amp; mkdir waveform_data
echo &amp;quot;export LAL_DATA_PATH=/&amp;lt;path_to_wave_data_dir&amp;gt;&amp;quot; &amp;gt;&amp;gt; .bash_profile
&lt;/code>&lt;/pre>
&lt;p>Copy the waveform data files and place them into this the &lt;code>waveform_data/&lt;/code> dir&lt;/p>
&lt;div class="alert alert-warning">
&lt;div>
Where do we get the waveform datafiles from again?
&lt;/div>
&lt;/div>
&lt;h2 id="test-install-with-the-following-script">Test install with the following script&lt;/h2>
&lt;script type="application/javascript" src="https://gist.github.com/avivajpeyi/030a544b097fcb4508055d73fa3fa895.js">&lt;/script></description></item></channel></rss>